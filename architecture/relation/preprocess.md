# 数据预处理和储存
- 数据预处理
- 数据清洗
- 数据集成
- 数据规范
- 数据离散化

## 数据预处理
### 原始数据的特点
- 不完整
	- 缺少属性值或仅仅包含聚集数据
- 含噪声
	- 包含错误或存在偏离期望的离群值 
	- 比如：salary=“-10”，明显是错误数据
- 不一致
	- 用于商品分类的部门编码存在差异
	- 比如age=“42”Birthday=“03/07/1997”

### 数据库数据的特点
一致性、准确性、完整性、时效性、可信性、可解释性

### 数据预处理的花费
由于获得的数据规模太过庞大，数据不完整、重复、杂乱，在一个完整的数据挖掘过程中，数据预处理要花费60%左右的时间

## 数据清洗
### 缺失值处理
- 忽略元组
	- 若有多个属性值缺失或者该元组剩余属性值使用价值较小时，应选择放弃
- 人工填写
	- 该方法费时，数据庞大时行不通
- 全局常量填充
	- 方法简单，但有可能会被挖掘程序愚以为形成了又去的概念
- 属性中心度量填充
	- 对于正常的数据分布而言可以使用均值，而倾斜数据分布应使用中位数
- **最可能的值填充**
	- **使用回归、基于推理的工具或者决策树归纳确定**

### 噪声数据与离群点
- 噪声
	- 被测量的变量的随机误差或者方差
	- 一般指错误的数据
- 离群点
	- 数据集中包含一些数据对象，他们与数据的一般行为或模型不一致
	- 正常值，但偏离大多数数据

### 分箱(binning)
通过考察数据周围的值来光滑有序数据值，这些有序的值被分布到一些“桶”或箱中，由于分箱方法只是考虑近邻的值，因此是局部光滑

**分箱的方法**
- 等宽分箱
    - 每个“桶”的区间宽度相同
- 等深分箱
	- 每个“桶”的样本个数相同

### 回归(regression)
用一个函数拟合数据来光滑数据

- 线性回归找出拟合两个属性（变量）的最佳直线
- 多元线性回归涉及多个属性，将数据拟合到多维曲面

## 数据集成
- 数据集成是把不同来源、格式、特点性质的数据在逻辑上或物理上有机的集中，从而为企业提供全面的数据共享
- 数据集成时，模式集成和对象匹配非常重要，如何将来自于多个信息源的等价实体进行匹配即实体识别问题
- 在进行数据集成时，同一数据在系统中多次重复出现，需要消除数据冗余，针对不同特征或数据间的关系进行相关性分析
- 相关性分析时用皮尔逊相关系数度量， 用于度量两个变量X和Y之间得相关（线性相关），其值介于1和-1之间

## 数据规范
### 数据规范策略
- 维度规约
	- 减少考虑的随机变量或属性的个数，或把原数据变换或投影到更小的空间
	- 具体方法
		- 小波变换、主成分分析等。
- 数量规约
	- 用替代的、较小的数据表示形式替换原数据 
	- 具体方法
		- 抽样和数据立方体聚集
- 数据压缩
	- 无损压缩
		- 能从压缩后的数据重构恢复原来的数据，不损失信息
	- 有损压缩
		- 只能近似重构原数据
	
### 数据规范方法
- 抽样
	- 分层抽样，系统抽样，整群抽样
	- 多阶段抽样
	- 基于Hash函数取样技术SHF
    	- 假设抽样n个数据，将[0,1]区间分成n份
    	- 输入全体数据，计算Hash函数将数据分配到n个桶中
    	- 每个桶中随机抽样一个样本，得到n个样本
- 主成分分析法(线性降维方法)
	- 在降维之后能最大程度的保持数据的内在信息，通过衡量在投影方向上的数据方差大小来衡量该方向的重要程度。
- 线性判别分析(有监督的线性降维方法)
	- 数据在降维后能很容易得被区分开，将高维的模式样本投影到最佳鉴别矢量空间，保证模式样本在新子空间内有最大类间距离和最小的类内距离，即模式在该空间中有最佳的可分离性。
- 局部线性嵌入LLE(非线性降维方法)
	- 能使降维后的数据保持原有的流形结构。如果数据分布在整个封闭的球面上，LLE则不能将其映射到二维空间，且不能保持原有的数据流形，于是在处理数据时首先要保证数据不在封闭的球面或者椭圆内
- 机器学习中的降维方法
	- PCA、LDA、LLE、Laplacian Eigenmaps

## 数据离散化
- 非监督离散化
	- 在离散过程中不考虑类别属性，其输入数据集仅含有待离散化属性的值。
假设属性的取值空间为X={X1,X2,⋯,Xn}，离散化之后的类标号是Y={Y1,Y2,⋯,Ym}，则无监督离散化的情况就是X已知而Y未知
	- 以下介绍几种常用的无监督离散化方法
		- 等宽算法 
			- 根据用户指定的区间数目K，将属性的值域[Xmin−Xmax]划分成K个区间，并使每个区间的宽度相等，即都等于Xmax−XminK。缺点是容易受离群点的影响而使性能不佳。 
		- 等频算法 
			- 等频算法也是根据用户自定义的区间数目，将属性的值域划分成K个小区间。他要求落在每个区间的对象数目相等。譬如，属性的取值区间内共有M个点，则等频区间所划分的K个小区域内，每个区域含有MK个点。 
		- K-means聚类算法 
			- 首先由用户指定离散化产生的区间数目K，K-均值算法首先从数据集中随机找出K个数据作为K个初始区间的重心；然后，根据这些重心的欧式距离，对所有的对象聚类：如果数据x距重心Gi最近，则将x划归Gi所代表的那个区间；然后重新计算各区间的重心，并利用新的重心重新聚类所有样本。逐步循环，直到所有区间的重心不再随算法循环而改变为止。
- 监督离散化
	- 输入数据包括类别信息（类标号），效果比无监督好
	- 具体方法
		- 齐次性的卡方检验
		- 自上而下的卡方分裂算法
		- ChiMerge算法
		- 基于熵的离散化方法